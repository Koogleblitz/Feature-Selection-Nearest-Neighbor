{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **[:+:] -- Feature Selection + Nearest Neighbor -- [:+:]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "#import seaborn as seab\n",
    "from itertools import chain, combinations\n",
    "#from scipy.spatial import minkowski_distance\n",
    "from numba import jit, cuda\n",
    "from timeit import default_timer as timer\n",
    "from math import comb\n",
    "# from itertools import combinations\n",
    "\n",
    "# [:::] --- TodDo  ---\n",
    "# - [x] Find \"default Rate\" : size(most common class)/size(dataset)\n",
    "# - [x] Create Minkowski Distance function for two points\n",
    "# - [x] Find nn of a single data point using only one feature\n",
    "# - [x] Get rid of spurrious percision\n",
    "# - [x] For small data, find nn of every data point using one feature + max accuracy\n",
    "# - [x] For small data, find nn of every data point using all features + max accuracy\n",
    "# - [x] Complete Forward selection for small datas set\n",
    "# - [x] GPU Multithreading for Classifier\n",
    "# - [x] Leave-One-Out Cross Validation\n",
    "# - [x] Complete Backward Elimination for small data set\n",
    "# - [x] Forward selection methods for large data set\n",
    "# - [x] Forward Selection validation for both datasets\n",
    "# - [x] Data Processing funtion\n",
    "# - [] Backelimination for large Data\n",
    "# - [] Data Viz\n",
    "# - [] Report\n",
    "# - [] User UI\n",
    "# - [] Third Feature\n",
    "# - [] Apend Data Processing function with distance matrix formation\n",
    "# - [] multithread everything else\n",
    "# - [] Find more brown m&ms\n",
    "# - [] Clean up the code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[+]** Read and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 4 entries of the first column: data[colIdx][rowIdx]:\n",
      "0    2.0\n",
      "1    1.0\n",
      "2    2.0\n",
      "3    2.0\n",
      "4    2.0\n",
      "Name: 0, dtype: float64\n",
      "<class 'numpy.float64'>\n",
      "\n",
      "Original Matrix Dimensions:\n",
      "(500, 7)\n",
      "Data Head:\n",
      "     0         1         2         3         4         5         6\n",
      "0  2.0 -1.101866 -0.782026  0.552502  0.454685  1.132363  1.135458\n",
      "1  1.0  0.928979 -0.169694  1.465293 -1.591929  0.144808  0.162709\n",
      "2  2.0  1.123118 -1.384730 -0.903598  0.692522  0.669263 -0.142156\n",
      "3  2.0  0.816617 -0.043628  1.026966  0.231013 -0.006551  2.316509\n",
      "4  2.0 -1.159129 -1.341375  0.459997  0.631261 -1.479455  0.520158\n",
      "MetaData: \n",
      "Occurrence counts of classes:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0\n",
       "1.0     95\n",
       "2.0    405\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Convert to numpy array to enable multithreading later:\n",
      "column size after conversion: 7\n",
      "column size after transposition: 500\n",
      "Dimensions after transposition: (7, 500)\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "#Read data from the text files and set as a pandas data frame\n",
    "lilData = pd.read_csv('CS170_Small_Data__19.txt', sep=\"  \", engine='python', header=None)\n",
    "bigData = pd.read_csv('CS170_Large_Data__3.txt', sep=\"  \", engine='python', header=None)\n",
    "\n",
    "print(\"\\nConvert to numpy array to enable multithreading later:\")\n",
    "lilData= lilData.to_numpy()\n",
    "bigData= bigData.to_numpy()\n",
    "print(\"column size after conversion: \" + str(len(data[0])))\n",
    "lilData= lilData.transpose()\n",
    "bigData= bigData.transpose()\n",
    "print(\"column size after transposition: \" + str(len(data[0])))\n",
    "print(\"Dimensions after transposition: \" + str(data.shape))\n",
    "print(type(lilData[0][0]))\n",
    "\n",
    "\n",
    "data= lilData\n",
    "#print all the data:\n",
    "#print(lilData)\n",
    "\n",
    "\n",
    "#----print just the 'label' column (and indeces):\n",
    "print(\"The first 4 entries of the first column: data[colIdx][rowIdx]:\")\n",
    "print(data[0][0:5])\n",
    "print(type(data[0][0]))\n",
    "\n",
    "\n",
    "print(\"\\nOriginal Matrix Dimensions:\")\n",
    "lil_rowXcol= data.shape\n",
    "print(lil_rowXcol)\n",
    "\n",
    "\n",
    "print(\"Data Head:\")\n",
    "print(data.head())\n",
    "\n",
    "print(\"MetaData: \")\n",
    "lilData.describe()\n",
    "\n",
    "\n",
    "\n",
    "print('Occurrence counts of classes:')\n",
    "# count occurrences of the class column\n",
    "occur = lilData.groupby([0]).size()\n",
    "# display occurrences of a particular column\n",
    "display(occur)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[+]** Minkowski Distance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My (from-scratch)Function takes in indices of two data points and exponent p, returns the minkowski distance between them based on the four dimensions and the exponent\n",
    "@jit(target_backend='cuda')\n",
    "def minkowski(data,rowIdx1,rowIdx2,ftSet,p):\n",
    "    # featSet1= []\n",
    "    # featSet2= []\n",
    "    sigma= 0\n",
    "    for ft in ftSet:\n",
    "        # featSet1.append(data[ft][rowIdx1])\n",
    "        # featSet2.append(data[ft][rowIdx2])\n",
    "        sigma+= ((((data[ft][rowIdx1]-data[ft][rowIdx2])**2))**(1/2))  **(p)\n",
    "        distance= sigma**(1/p)\n",
    "    return distance\n",
    "    # return distance, featSet1, featSet2\n",
    "\n",
    "# d= minkowski(lilData, rowIdx1=1, rowIdx2= 2, ftSet=(1,2,3,4,5,6), p=2)\n",
    "# print(d)\n",
    "# minkowski_distance(d[1],d[2],p=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[:+:]** Forward Selection **+** Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\AppData\\Local\\Temp\\ipykernel_33392\\1522238391.py:222: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ftComboList= np.array([quadruplets, triplets, doubles, singles])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 2.0, 3.0, 4.0), (1.0, 2.0, 3.0, 5.0)]\n",
      "[(1.0, 2.0, 3.0), (1.0, 2.0, 4.0)]\n",
      "[(1.0, 2.0), (1.0, 3.0)]\n",
      "[(1.0,), (2.0,)]\n",
      "        - Testing with features [1 2 3 4] | Accuracy: %71.8\n",
      "        - Testing with features [1 2 3 5] | Accuracy: %86.8\n",
      "        - Testing with features [1 2 3 6] | Accuracy: %71.4\n",
      "        - Testing with features [1 2 4 5] | Accuracy: %87.0\n",
      "        - Testing with features [1 2 4 6] | Accuracy: %71.8\n",
      "        - Testing with features [1 2 5 6] | Accuracy: %91.8\n",
      "        - Testing with features [1 3 4 5] | Accuracy: %86.4\n",
      "        - Testing with features [1 3 4 6] | Accuracy: %77.2\n",
      "        - Testing with features [1 3 5 6] | Accuracy: %89.2\n",
      "        - Testing with features [1 4 5 6] | Accuracy: %88.2\n",
      "        - Testing with features [2 3 4 5] | Accuracy: %78.0\n",
      "        - Testing with features [2 3 4 6] | Accuracy: %70.4\n",
      "        - Testing with features [2 3 5 6] | Accuracy: %80.8\n",
      "        - Testing with features [2 4 5 6] | Accuracy: %78.8\n",
      "        - Testing with features [3 4 5 6] | Accuracy: %81.6\n",
      "     [-] -- we eliminate feature [[]], and end up with feature set: [1 2 5 6] with an accuracy of %91.8\n",
      "                                        [:-:] Eliminated so far:--->[]\n",
      "\n",
      "        - Testing with features [1 2 3] | Accuracy: %70.2\n",
      "        - Testing with features [1 2 4] | Accuracy: %70.4\n",
      "        - Testing with features [1 2 5] | Accuracy: %91.2\n",
      "        - Testing with features [1 2 6] | Accuracy: %73.0\n",
      "        - Testing with features [1 3 4] | Accuracy: %75.4\n",
      "        - Testing with features [1 3 5] | Accuracy: %91.4\n",
      "        - Testing with features [1 3 6] | Accuracy: %72.0\n",
      "        - Testing with features [1 4 5] | Accuracy: %93.4\n",
      "        - Testing with features [1 4 6] | Accuracy: %73.0\n",
      "        - Testing with features [1 5 6] | Accuracy: %94.4\n",
      "        - Testing with features [2 3 4] | Accuracy: %68.4\n",
      "        - Testing with features [2 3 5] | Accuracy: %81.4\n",
      "        - Testing with features [2 3 6] | Accuracy: %71.2\n",
      "        - Testing with features [2 4 5] | Accuracy: %80.8\n",
      "        - Testing with features [2 4 6] | Accuracy: %70.8\n",
      "        - Testing with features [2 5 6] | Accuracy: %85.2\n",
      "        - Testing with features [3 4 5] | Accuracy: %81.4\n",
      "        - Testing with features [3 4 6] | Accuracy: %73.0\n",
      "        - Testing with features [3 5 6] | Accuracy: %81.6\n",
      "        - Testing with features [4 5 6] | Accuracy: %84.4\n",
      "     [-] -- we eliminate feature [[2]], and end up with feature set: [1 5 6] with an accuracy of %94.4\n",
      "                                        [:-:] Eliminated so far:--->[2.]\n",
      "\n",
      "        - Testing with features [1 3] | Accuracy: %73.6\n",
      "        - Testing with features [1 4] | Accuracy: %72.0\n",
      "        - Testing with features [1 5] | Accuracy: %96.2\n",
      "        - Testing with features [1 6] | Accuracy: %71.4\n",
      "        - Testing with features [3 4] | Accuracy: %70.8\n",
      "        - Testing with features [3 5] | Accuracy: %82.0\n",
      "        - Testing with features [3 6] | Accuracy: %69.0\n",
      "        - Testing with features [4 5] | Accuracy: %83.4\n",
      "        - Testing with features [4 6] | Accuracy: %68.8\n",
      "        - Testing with features [5 6] | Accuracy: %85.4\n",
      "     [-] -- we eliminate feature [[6]], and end up with feature set: [1 5] with an accuracy of %96.2\n",
      "                                        [:-:] Eliminated so far:--->[2. 6.]\n",
      "\n",
      "        - Testing with features [1] | Accuracy: %72.4\n",
      "        - Testing with features [3] | Accuracy: %68.0\n",
      "        - Testing with features [4] | Accuracy: %68.6\n",
      "        - Testing with features [5] | Accuracy: %85.6\n",
      "     [-] -- we eliminate feature [[6]], and end up with feature set: [5] with an accuracy of %85.6\n",
      "After eliminating all features, we  und up with a default rate of: 0.81\n",
      "\n",
      "[:+:] ---  Backward Selection Results: The best set of features is [1 5] | Accuracy: %96.2  --- [:+:]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([(0.918, 3), (0.944, 3), (0.962, 3)],\n",
       " [(array([1, 2, 5, 6]), 3), (array([1, 5, 6]), 3), (array([1, 5]), 3)])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @jit(nopython=False)\n",
    "def generateFtCombos(data, limit=6):\n",
    "    # features= np.empty(0)\n",
    "    # ftCombos= np.empty(0)\n",
    "    features= np.empty(0).astype(int)\n",
    "    ftCombos= []\n",
    "    ftRow= data.shape[0]\n",
    "    for i in range(1,ftRow):\n",
    "        features= np.append(features, i)\n",
    "    for ft in range(1, limit):\n",
    "        for combo in itertools.combinations(features, ft):\n",
    "            ftCombos.append(combo)\n",
    "    return features, (ftCombos)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# @jit(target_backend='cuda')\n",
    "def generateDefaultRate(data):\n",
    "    classCnt= [0,0]\n",
    "    for pt in data[0]:\n",
    "        if pt==1:\n",
    "            classCnt[0]+= 1\n",
    "        else:\n",
    "            classCnt[1]+= 1\n",
    "    defaultRate= max(classCnt)/(classCnt[0]+classCnt[1])\n",
    "    return defaultRate\n",
    "\n",
    "\n",
    "# takes a single combo of features, classifies each dp by its nearest neighbor, returns a list of classifications for every dp\n",
    "@jit(target_backend='cuda')\n",
    "def classifier(data, ftSet):\n",
    "    rows= data.shape[1]\n",
    "    nearestNeighbors= np.empty(0)\n",
    "    for dp in range(0,rows):\n",
    "        nnIdx= 0\n",
    "        nearest= 10000\n",
    "        classification= 0\n",
    "        for  neighborIdx in range(0,rows):\n",
    "            if dp != neighborIdx:\n",
    "                dist= minkowski(data, dp, neighborIdx, ftSet, p=2)\n",
    "                if dist < nearest:\n",
    "                    nnIdx= neighborIdx\n",
    "                    nearest= dist\n",
    "        classification= data[0][nnIdx]\n",
    "        nearestNeighbors= np.append(nearestNeighbors, classification)\n",
    "    return nearestNeighbors\n",
    "\n",
    "\n",
    "#  Returns the accuracy of the classifier tested with a combination of features (leave-one-out, k=n)\n",
    "# @jit(target_backend='cuda')\n",
    "def crossValidate(data, ftSet):\n",
    "    classes= classifier(data, ftSet)\n",
    "    classesL= len(classes)\n",
    "    correct= 0\n",
    "    for j in range(0,classesL):\n",
    "        if classes[j] == data[0][j]:\n",
    "            correct+=1\n",
    "    accuracy = correct/classesL\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# @jit(target_backend='cuda')\n",
    "def forwardSelection(data, prevFtSet=np.asarray([]),finalAccuracy=0, finalSet=np.asarray([])):\n",
    "    ftSetLen= len(prevFtSet)\n",
    "    ftRowLength= data.shape[0]\n",
    "    if ftSetLen>= ftRowLength-1:\n",
    "        bestFtSet= finalSet\n",
    "        print(\"[:+:] ---  Forward Selection Results: The best set of features is \" +str(bestFtSet)+ \" | Accuracy: %\" +str(round(finalAccuracy*100,3))+ \"  --- [:+:]\")\n",
    "    else:\n",
    "        print(\"[::] -- Forward Selection Search Tree Level \"+str(ftSetLen+1)+ \" -- [::]\" )\n",
    "        if ftSetLen==0:\n",
    "            print(\"        - Testing without features  | Default Rate: %\" + str(round(generateDefaultRate(data)*100,3)))\n",
    "        bestAcc= 0\n",
    "        bestFtSubset= np.empty(0)\n",
    "        for ft in range(1, ftRowLength):\n",
    "            ftSet= np.empty(0)\n",
    "            if ft not in prevFtSet:\n",
    "                ftSet= np.append(prevFtSet, ft).astype(int)\n",
    "                ftAccuracy= crossValidate(data,ftSet)\n",
    "                print(\"        - Testing with features \"+ str(ftSet) + \" | Accuracy: %\" + str(round(ftAccuracy*100,3)))\n",
    "                if ftAccuracy>bestAcc: \n",
    "                    bestAcc= ftAccuracy\n",
    "                    bestFtSubset= ftSet\n",
    "        if bestAcc>finalAccuracy:\n",
    "            finalSet= bestFtSubset\n",
    "            finalAccuracy= bestAcc\n",
    "        print(\"     [+] -- On level \"+str(ftSetLen+1)+ \", we add feature subset \" + str(bestFtSubset)+\" with an accuracy of %\" + str(round(bestAcc*100,3))+ \"\\n\")\n",
    "        bestFtSet=  forwardSelection(data, bestFtSubset,finalAccuracy, finalSet)\n",
    "    return bestFtSet\n",
    "\n",
    "\n",
    "\n",
    "def backwardElimination(data, prevFtSet=np.empty(0), eliminated=np.empty(0), globalAcc=0, globalFts=np.empty(0)):\n",
    "    ftRowL= data.shape[0]\n",
    "    if ftRowL<10:\n",
    "        ftCombos= generateFtCombos(data)[1]\n",
    "    else:\n",
    "        # ftSetNew= (generateFeatures(ftRowL))\n",
    "        # ftCombos= getTriplets(np.asarray(ftSetNew))\n",
    "        ftCombos= generateFtCombos(data,limit=3)[1]\n",
    "    \n",
    "    bestAcc= 0\n",
    "    bestFts= np.empty(0)\n",
    "    prevComboL= len(prevFtSet)\n",
    "    leveL= ftRowL - prevComboL\n",
    "    elimCandidate= []\n",
    "    print(\"[::] -- Backward Elimination Search Tree Level \"+str(leveL)+ \" -- [::]\" )\n",
    "    if(prevComboL==1):\n",
    "        defaultRate= generateDefaultRate(data)\n",
    "        print(\"After eliminating all features, we  und up with a default rate of: \" +str(defaultRate))\n",
    "        print(\"\\n[:+:] ---  Backward Selection Results: The best set of features is \" +str(globalFts)+ \" | Accuracy: %\" +str(round(globalAcc*100,3))+ \"  --- [:+:]\")\n",
    "        return globalFts, globalAcc\n",
    "    else:\n",
    "        if(prevComboL==ftRowL-1):\n",
    "            print(\"        - Testing with features \"+ str(prevFtSet) + \" | Accuracy: %\" + str(round(crossValidate(data, prevFtSet )*100,3)))\n",
    "        for i in range(0, len(ftCombos)):\n",
    "            ftSet= np.empty(0)\n",
    "            combo= set(ftCombos[i])\n",
    "            if (len(combo)==(prevComboL-1)):\n",
    "                commonElmtCnt= len(combo.intersection(eliminated))\n",
    "                if(commonElmtCnt==0):\n",
    "                    ftSet= np.append(ftSet, list(combo)).astype(int)\n",
    "                    ftAccuracy= crossValidate(data, ftSet )\n",
    "                    print(\"        - Testing with features \"+ str(ftSet) + \" | Accuracy: %\" + str(round(ftAccuracy*100,3)))\n",
    "                    if ftAccuracy>bestAcc:\n",
    "                        bestAcc= ftAccuracy\n",
    "                        bestFts= ftSet\n",
    "                        elimCandidate= list(set(prevFtSet).difference((combo)))[0]\n",
    "        eliminated= np.append(eliminated, elimCandidate).astype(int)\n",
    "        print(\"     [-] -- On level \"+str(leveL)+ \", we eliminate feature [\"+ str(elimCandidate)+\"], and end up with feature set: \" + str(bestFts)+\" with an accuracy of %\" + str(round(bestAcc*100,3)))\n",
    "        print(\"                                        [:-:] Eliminated so far:--->\"+ str(eliminated)+ \"\\n\")\n",
    "        if bestAcc>globalAcc:\n",
    "            globalAcc= bestAcc\n",
    "            globalFts= bestFts\n",
    "        return backwardElimination(data, bestFts,eliminated, globalAcc, globalFts)\n",
    "\n",
    "\n",
    "\n",
    "def exhaustiveSelection(data):\n",
    "    bestAcc= 0\n",
    "    bestFt= np.empty(0)\n",
    "    for combo in generateFtCombos(data)[1]:\n",
    "        ftSet= np.empty(0)      \n",
    "        ftSet= np.append(ftSet, combo).astype(int)\n",
    "        ftAccuracy= crossValidate(data, ftSet )\n",
    "        print(\"        - Testing with features \"+ str(ftSet) + \" | Accuracy: %\" + str(round(ftAccuracy*100,3)))\n",
    "        if ftAccuracy>bestAcc:\n",
    "            bestAcc= ftAccuracy\n",
    "            bestFt= ftSet\n",
    "    return bestFt, bestAcc\n",
    "\n",
    "# @jit(nopython=True)\n",
    "@jit(target_backend='cuda')\n",
    "def generateFeatures(ftRowL=0):\n",
    "    # if ftRowL==0:\n",
    "    #     ftRowL= data.shape[0]\n",
    "    features= np.empty(0)\n",
    "    for i in range(1,ftRowL):\n",
    "        features= np.append(features, i)\n",
    "    return features\n",
    "\n",
    "@jit(target_backend='cuda')\n",
    "def tripleSplits(triplet):\n",
    "    trippled= len(triplet)\n",
    "    size= trippled//3\n",
    "    triSplit= np.empty([size,3])\n",
    "    triSplit= np.empty(0)\n",
    "    for i in range(0,trippled):\n",
    "\n",
    "        if i%3==0:\n",
    "            triSplit[i//3][0]= triplet[i-2]\n",
    "            triSplit[i//3][1]= triplet[i-1]\n",
    "            triSplit[i//3][2]= triplet[i]\n",
    "    return triSplit\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@jit(target_backend='cuda')\n",
    "def generateTriplets(ftRowL, setL=3, prevSet=np.array([]),rezSet= np.empty(0),tripletSet= np.empty(0) ):\n",
    "    if len(prevSet)==setL:\n",
    "        #print(\"return prevset\")\n",
    "        return prevSet\n",
    "    fts= generateFeatures(ftRowL)\n",
    "    for ft in fts:\n",
    "        if ft not in prevSet:\n",
    "            newFtSet= np.copy(prevSet)\n",
    "            newFtSet= np.append(newFtSet,ft)\n",
    "            brandNewFtSet= generateTriplets((ftRowL-1),setL,prevSet=newFtSet, tripletSet=tripletSet)\n",
    "            #print(brandNewFtSet)\n",
    "            tripletSet= np.concatenate(( tripletSet,brandNewFtSet))\n",
    "    #print(\"return tripletSet\")\n",
    "    return tripletSet\n",
    "\n",
    "\n",
    "\n",
    "def getTriplets(ftSet,limit=3):\n",
    "    triplets= []\n",
    "    for comb in itertools.combinations(ftSet, limit):\n",
    "        # comb= (np.asarray(comb))\n",
    "        # triplets= np.append(triplets,comb)\n",
    "        triplets.append(comb)\n",
    "    return (triplets)\n",
    "\n",
    "def bigDataBacklimination(data):\n",
    "    length= data.shape[0]\n",
    "\n",
    "    features= (generateFeatures(length))\n",
    "\n",
    "    quadruplets= getTriplets(np.asarray(features),4)\n",
    "    triplets= getTriplets(np.asarray(features),3)\n",
    "    doubles= getTriplets(np.asarray(features),2)\n",
    "    singles= getTriplets(np.asarray(features),1)\n",
    "\n",
    "    ftComboList= np.array([quadruplets, triplets, doubles, singles])\n",
    "\n",
    "    for i in range(0,4):\n",
    "        print(ftComboList[i][0:2])\n",
    "    #ftCombos= generateFtCombos(data,limit=3)[1]\n",
    "\n",
    "    bestGlobalAcc= 0\n",
    "    bestGlobalSet= np.empty(0)\n",
    "    ftGlobals= []\n",
    "    accGlobals= []\n",
    "    \n",
    "    exclusion= np.empty(0)\n",
    "    for comboList in ftComboList:\n",
    "        bestLocalAcc= 0\n",
    "        bestLocalSet= np.empty(0)\n",
    "        for  combo in comboList:\n",
    "            common= np.intersect1d(combo, exclusion)\n",
    "            if len(common)==0:\n",
    "                ftSet= np.empty(0)      \n",
    "                ftSet= np.append(ftSet, combo).astype(int)\n",
    "                ftAcc= crossValidate(data, ftSet )\n",
    "                print(\"        - Testing with features \"+ str(ftSet) + \" | Accuracy: %\" + str(round(ftAcc*100,3)))\n",
    "                if ftAcc>bestLocalAcc:\n",
    "                    bestLocalAcc= ftAcc\n",
    "                    bestLocalSet= ftSet\n",
    "        if bestLocalAcc>bestGlobalAcc:\n",
    "            setDiff= np.setdiff1d(bestGlobalSet,bestLocalSet)\n",
    "            exclusion= np.append(exclusion, setDiff)\n",
    "            bestGlobalAcc= bestLocalAcc\n",
    "            bestGlobalSet= bestLocalSet\n",
    "            ftGlobals.append(  (bestLocalAcc,3)  )  \n",
    "            accGlobals.append(  (bestLocalSet,3)  )\n",
    "            print(\"     [-] -- we eliminate feature [\"+ str(setDiff)+\"], and end up with feature set: \" + str(bestLocalSet)+\" with an accuracy of %\" + str(round(bestLocalAcc*100,3)))\n",
    "            print(\"                                        [:-:] Eliminated so far:--->\"+ str(exclusion)+ \"\\n\")\n",
    "    print(\"     [-] -- we eliminate feature [\"+ str(setDiff)+\"], and end up with feature set: \" + str(bestLocalSet)+\" with an accuracy of %\" + str(round(bestLocalAcc*100,3)))\n",
    "    defaultRate= generateDefaultRate(data)\n",
    "    print(\"After eliminating all features, we  und up with a default rate of: \" +str(defaultRate))\n",
    "    print(\"\\n[:+:] ---  Backward Selection Results: The best set of features is \" +str(bestGlobalSet)+ \" | Accuracy: %\" +str(round(bestGlobalAcc*100,3))+ \"  --- [:+:]\")\n",
    "    return ftGlobals, accGlobals\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fuck= generateFtCombos(data)\n",
    "# print(fuck)\n",
    "# print(len(fuck))\n",
    "\n",
    "bigDataBacklimination(lilData)\n",
    "\n",
    "# print(\"split triple set:\")\n",
    "# print(len(tripletSet))\n",
    "# print(tripletSet[0:5])\n",
    "# featureCombos= generateFtCombos(data)\n",
    "# ftSet= featureCombos[0]\n",
    "# ftCombos= featureCombos[1]\n",
    "# print(ftSet)\n",
    "\n",
    "# triplets= (generateTriplets(data.shape[0]))\n",
    "# triplets= np.split(triplets, (len(triplets)/3))\n",
    "# print(triplets)\n",
    "# print(len(triplets))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "\n",
    "# start = timer()\n",
    "# print(forwardSelection(data))\n",
    "# print(\"Time without GPU:\", timer()-start)\n",
    "\n",
    "# start = timer()\n",
    "# print(backwardElimination(data, np.asarray([1,2,3,4,5,6])))\n",
    "# print(\"Time without GPU:\", timer()-start)\n",
    "\n",
    "\n",
    "# start = timer()\n",
    "# print(exhaustiveSelection(data))\n",
    "# print(\"Time without GPU:\", timer()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **[:+:] Notes**\n",
    "-   The best single feature is #5, with an accuracy of 0.856"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Works Cited:\n",
    "\n",
    "\n",
    "-   https://www.analyticsvidhya.com/blog/2020/02/4-types-of-distance-metrics-in-machine-learning/\n",
    "\n",
    "-   https://www.geeksforgeeks.org/pandas-groupby-count-occurrences-in-column/\n",
    "-   https://www.codingem.com/python-how-to-get-all-combinations-of-a-list/\n",
    "-   https://www.geeksforgeeks.org/running-python-script-on-gpu/\n",
    "-   https://www.programiz.com/python-programming/methods/set/intersection\n",
    "-   https://www.youtube.com/watch?v=nh2IGC_kLWw\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d452713d07931529b46a6a4adbae9c48126cf3f4bc3a50be39ac3715dec6caaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
