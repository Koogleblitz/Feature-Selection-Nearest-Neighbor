{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **[:+:] Feature Selection + Nearest Neighbor [:+:]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "#import seaborn as seab\n",
    "from itertools import chain, combinations\n",
    "#from scipy.spatial import minkowski_distance\n",
    "from numba import jit, cuda\n",
    "from timeit import default_timer as timer\n",
    "# from itertools import combinations\n",
    "\n",
    "# [:::] --- TodDo  ---\n",
    "# - [x] Find \"default Rate\" : size(most common class)/size(dataset)\n",
    "# - [x] Create Minkowski Distance function for two points\n",
    "# - [x] Find nn of a single data point using only one feature\n",
    "# - [x] Get rid of spurrious percision\n",
    "# - [x] For small data, find nn of every data point using one feature + max accuracy\n",
    "# - [x] For small data, find nn of every data point using all features + max accuracy\n",
    "# - [x] Complete Forward selection for small datas set\n",
    "# - [x] GPU Multithreading for Classifier\n",
    "# - [x] Leave-One-Out Cross Validation\n",
    "# - [] Complete Backward Elimination for small data set\n",
    "# - [] Complete Both selection methods for large data set\n",
    "# - [] multithread everything else\n",
    "# - [] Data Viz\n",
    "# - [] Report\n",
    "# - [] Find more brown m&ms\n",
    "# - [] Clean up the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[+] Reading the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 4 entries of the first column: data[colIdx][rowIdx]:\n",
      "0    2.0\n",
      "1    1.0\n",
      "2    2.0\n",
      "3    2.0\n",
      "4    2.0\n",
      "Name: 0, dtype: float64\n",
      "<class 'numpy.float64'>\n",
      "\n",
      "Original Matrix Dimensions:\n",
      "(500, 7)\n",
      "Data Head:\n",
      "     0         1         2         3         4         5         6\n",
      "0  2.0 -1.101866 -0.782026  0.552502  0.454685  1.132363  1.135458\n",
      "1  1.0  0.928979 -0.169694  1.465293 -1.591929  0.144808  0.162709\n",
      "2  2.0  1.123118 -1.384730 -0.903598  0.692522  0.669263 -0.142156\n",
      "3  2.0  0.816617 -0.043628  1.026966  0.231013 -0.006551  2.316509\n",
      "4  2.0 -1.159129 -1.341375  0.459997  0.631261 -1.479455  0.520158\n",
      "MetaData: \n",
      "Occurrence counts of classes:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0\n",
       "1.0     95\n",
       "2.0    405\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Convert to numpy array to enable multithreading later:\n",
      "column size after conversion: 7\n",
      "column size after transposition: 500\n",
      "Dimensions after transposition: (7, 500)\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "#Read data from the text files and set as a pandas data frame\n",
    "data = pd.read_csv('CS170_Small_Data__19.txt', sep=\"  \", engine='python', header=None)\n",
    "\n",
    "\n",
    "#print all the data:\n",
    "#print(lilData)\n",
    "\n",
    "\n",
    "#----print just the 'label' column (and indeces):\n",
    "print(\"The first 4 entries of the first column: data[colIdx][rowIdx]:\")\n",
    "print(data[0][0:5])\n",
    "print(type(data[0][0]))\n",
    "\n",
    "\n",
    "print(\"\\nOriginal Matrix Dimensions:\")\n",
    "lil_rowXcol= data.shape\n",
    "print(lil_rowXcol)\n",
    "\n",
    "\n",
    "print(\"Data Head:\")\n",
    "print(data.head())\n",
    "\n",
    "print(\"MetaData: \")\n",
    "data.describe()\n",
    "\n",
    "\n",
    "\n",
    "print('Occurrence counts of classes:')\n",
    "# count occurrences of the class column\n",
    "occur = data.groupby([0]).size()\n",
    "# display occurrences of a particular column\n",
    "display(occur)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nConvert to numpy array to enable multithreading later:\")\n",
    "data= data.to_numpy()\n",
    "print(\"column size after conversion: \" + str(len(data[0])))\n",
    "data= data.transpose()\n",
    "print(\"column size after transposition: \" + str(len(data[0])))\n",
    "print(\"Dimensions after transposition: \" + str(data.shape))\n",
    "\n",
    "print(type(data[0][0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[+] Minkowski Distance Calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My (from-scratch)Function takes in indices of two data points and exponent p, returns the minkowski distance between them based on the four dimensions and the exponent\n",
    "@jit(target_backend='cuda')\n",
    "def minkowski(data,rowIdx1,rowIdx2,ftSet,p):\n",
    "    # featSet1= []\n",
    "    # featSet2= []\n",
    "    sigma= 0\n",
    "    for ft in ftSet:\n",
    "        # featSet1.append(data[ft][rowIdx1])\n",
    "        # featSet2.append(data[ft][rowIdx2])\n",
    "        sigma+= ((((data[ft][rowIdx1]-data[ft][rowIdx2])**2))**(1/2))  **(p)\n",
    "        distance= sigma**(1/p)\n",
    "    return distance\n",
    "    # return distance, featSet1, featSet2\n",
    "\n",
    "# d= minkowski(lilData, rowIdx1=1, rowIdx2= 2, ftSet=(1,2,3,4,5,6), p=2)\n",
    "# print(d)\n",
    "# minkowski_distance(d[1],d[2],p=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **[:+:] Forward Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[::] -- Backward Elimination Search Tree Level 1 -- [::]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\richa\\anaconda3\\lib\\site-packages\\numba\\core\\ir_utils.py:2139: NumbaPendingDeprecationWarning: \u001b[1m\n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'ftSet' of function 'classifier'.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_29576\\1571213009.py\", line 29:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        - Testing with features [1, 2, 3, 4, 5, 6] | Accuracy: %81.6\n",
      "        - Testing with features [1 2 3 4 5] | Accuracy: %83.0\n",
      "        - Testing with features [1 2 3 4 6] | Accuracy: %70.4\n",
      "        - Testing with features [1 2 3 5 6] | Accuracy: %85.0\n",
      "        - Testing with features [1 2 4 5 6] | Accuracy: %84.8\n",
      "        - Testing with features [1 3 4 5 6] | Accuracy: %84.8\n",
      "        - Testing with features [2 3 4 5 6] | Accuracy: %77.4\n",
      "[-] -- On level 1, we eliminate feature [4], and end up with feature set: [1 2 3 5 6] with an accuracy of %85.0\n",
      "                                        [:-:] Eliminated so far:--->[4]\n",
      "\n",
      "[::] -- Backward Elimination Search Tree Level 2 -- [::]\n",
      "        - Testing with features [1 2 3 5] | Accuracy: %86.8\n",
      "        - Testing with features [1 2 3 6] | Accuracy: %71.4\n",
      "        - Testing with features [1 2 5 6] | Accuracy: %91.8\n",
      "        - Testing with features [1 3 5 6] | Accuracy: %89.2\n",
      "        - Testing with features [2 3 5 6] | Accuracy: %80.8\n",
      "[-] -- On level 2, we eliminate feature [3], and end up with feature set: [1 2 5 6] with an accuracy of %91.8\n",
      "                                        [:-:] Eliminated so far:--->[4 3]\n",
      "\n",
      "[::] -- Backward Elimination Search Tree Level 3 -- [::]\n",
      "        - Testing with features [1 2 5] | Accuracy: %91.2\n",
      "        - Testing with features [1 2 6] | Accuracy: %73.0\n",
      "        - Testing with features [1 5 6] | Accuracy: %94.4\n",
      "        - Testing with features [2 5 6] | Accuracy: %85.2\n",
      "[-] -- On level 3, we eliminate feature [2], and end up with feature set: [1 5 6] with an accuracy of %94.4\n",
      "                                        [:-:] Eliminated so far:--->[4 3 2]\n",
      "\n",
      "[::] -- Backward Elimination Search Tree Level 4 -- [::]\n",
      "        - Testing with features [1 5] | Accuracy: %96.2\n",
      "        - Testing with features [1 6] | Accuracy: %71.4\n",
      "        - Testing with features [5 6] | Accuracy: %85.4\n",
      "[-] -- On level 4, we eliminate feature [6], and end up with feature set: [1 5] with an accuracy of %96.2\n",
      "                                        [:-:] Eliminated so far:--->[4 3 2 6]\n",
      "\n",
      "[::] -- Backward Elimination Search Tree Level 5 -- [::]\n",
      "        - Testing with features [1] | Accuracy: %72.4\n",
      "        - Testing with features [5] | Accuracy: %85.6\n",
      "[-] -- On level 5, we eliminate feature [1], and end up with feature set: [5] with an accuracy of %85.6\n",
      "                                        [:-:] Eliminated so far:--->[4 3 2 6 1]\n",
      "\n",
      "[::] -- Backward Elimination Search Tree Level 6 -- [::]\n",
      "After eliminating all features, we  und up with a default rate of: 0.81\n",
      "\n",
      "[:+:] ---  Backward Selection Results: The best set of features is [1 5] | Accuracy: %96.2  --- [:+:]\n",
      "(array([1, 5]), 0.962)\n"
     ]
    }
   ],
   "source": [
    "# @jit(target_backend='cuda')\n",
    "def generateCombos(data):\n",
    "    features= []\n",
    "    ftCombos= []\n",
    "    ftRow= data.shape[0]\n",
    "    for i in range(1,ftRow):\n",
    "        features.append(i)\n",
    "    for ft in features:\n",
    "        for combo in itertools.combinations(features, ft):\n",
    "            ftCombos.append(combo)\n",
    "    return (ftCombos)\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "# @jit(target_backend='cuda')\n",
    "def generateDefaultRate(data):\n",
    "    classCnt= [0,0]\n",
    "    for pt in data[0]:\n",
    "        if pt==1:\n",
    "            classCnt[0]+= 1\n",
    "        else:\n",
    "            classCnt[1]+= 1\n",
    "    defaultRate= max(classCnt)/(classCnt[0]+classCnt[1])\n",
    "    return defaultRate\n",
    "\n",
    "\n",
    "# takes a single combo of features, classifies each dp by its nearest neighbor, returns a list of classifications for every dp\n",
    "@jit(target_backend='cuda')\n",
    "def classifier(data, ftSet):\n",
    "    rows= data.shape[1]\n",
    "    nearestNeighbors= np.empty(0)\n",
    "    for dp in range(0,rows):\n",
    "        nnIdx= 0\n",
    "        nearest= 10000\n",
    "        classification= 0\n",
    "        for  neighborIdx in range(0,rows):\n",
    "            if dp != neighborIdx:\n",
    "                dist= minkowski(data, dp, neighborIdx, ftSet, p=2)\n",
    "                if dist < nearest:\n",
    "                    nnIdx= neighborIdx\n",
    "                    nearest= dist\n",
    "        classification= data[0][nnIdx]\n",
    "        nearestNeighbors= np.append(nearestNeighbors, classification)\n",
    "    return nearestNeighbors\n",
    "\n",
    "\n",
    "#  Returns the accuracy of the classifier tested with a combination of features (leave-one-out, k=n)\n",
    "# @jit(target_backend='cuda')\n",
    "def crossValidate(data, ftSet):\n",
    "    classes= classifier(data, ftSet)\n",
    "    classesL= len(classes)\n",
    "    correct= 0\n",
    "    for j in range(0,classesL):\n",
    "        if classes[j] == data[0][j]:\n",
    "            correct+=1\n",
    "    accuracy = correct/classesL\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# @jit(target_backend='cuda')\n",
    "def forwardSelection(data, prevFtSet=np.asarray([]),finalAccuracy=0, finalSet=np.asarray([])):\n",
    "    ftSetLen= len(prevFtSet)\n",
    "    ftRowLength= data.shape[0]\n",
    "    if ftSetLen>= ftRowLength-1:\n",
    "        bestFtSet= finalSet\n",
    "        print(\"[:+:] ---  Forward Selection Results: The best set of features is \" +str(bestFtSet)+ \" | Accuracy: %\" +str(round(finalAccuracy*100,3))+ \"  --- [:+:]\")\n",
    "    else:\n",
    "        print(\"[::] -- Forward Selection Search Tree Level \"+str(ftSetLen+1)+ \" -- [::]\" )\n",
    "        if ftSetLen==0:\n",
    "            print(\"        - Testing without features  | Default Rate: %\" + str(round(generateDefaultRate(data)*100,3)))\n",
    "        bestAcc= 0\n",
    "        bestFtSubset= np.empty(0)\n",
    "        for ft in range(1, ftRowLength):\n",
    "            ftSet= np.empty(0)\n",
    "            if ft not in prevFtSet:\n",
    "                ftSet= np.append(prevFtSet, ft).astype(int)\n",
    "                ftAccuracy= crossValidate(data,ftSet)\n",
    "                print(\"        - Testing with features \"+ str(ftSet) + \" | Accuracy: %\" + str(round(ftAccuracy*100,3)))\n",
    "                if ftAccuracy>bestAcc: \n",
    "                    bestAcc= ftAccuracy\n",
    "                    bestFtSubset= ftSet\n",
    "        if bestAcc>finalAccuracy:\n",
    "            finalSet= bestFtSubset\n",
    "            finalAccuracy= bestAcc\n",
    "        print(\"[+] -- On level \"+str(ftSetLen+1)+ \", we add feature subset \" + str(bestFtSubset)+\" with an accuracy of %\" + str(round(bestAcc*100,3))+ \"\\n\")\n",
    "        bestFtSet=  forwardSelection(data, bestFtSubset,finalAccuracy, finalSet)\n",
    "    return bestFtSet\n",
    "\n",
    "\n",
    "\n",
    "def backwardElimination(data, prevFtSet=np.empty(0), eliminated=np.empty(0), globalAcc=0, globalFts=np.empty(0)):\n",
    "    ftCombos= generateCombos(data)\n",
    "    ftRowL= data.shape[0]\n",
    "    bestAcc= 0\n",
    "    bestFts= np.empty(0)\n",
    "    prevComboL= len(prevFtSet)\n",
    "    leveL= ftRowL - prevComboL\n",
    "    elimCandidate= []\n",
    "    print(\"[::] -- Backward Elimination Search Tree Level \"+str(leveL)+ \" -- [::]\" )\n",
    "    if(prevComboL==1):\n",
    "        defaultRate= generateDefaultRate(data)\n",
    "        print(\"After eliminating all features, we  und up with a default rate of: \" +str(defaultRate))\n",
    "        print(\"\\n[:+:] ---  Backward Selection Results: The best set of features is \" +str(globalFts)+ \" | Accuracy: %\" +str(round(globalAcc*100,3))+ \"  --- [:+:]\")\n",
    "        return globalFts, globalAcc\n",
    "    else:\n",
    "        if(prevComboL==ftRowL-1):\n",
    "            print(\"        - Testing with features \"+ str(prevFtSet) + \" | Accuracy: %\" + str(round(crossValidate(data, prevFtSet )*100,3)))\n",
    "        for i in range(0, len(ftCombos)):\n",
    "            ftSet= np.empty(0)\n",
    "            combo= set(ftCombos[i])\n",
    "            if (len(combo)==(prevComboL-1)):\n",
    "                commonElmtCnt= len(combo.intersection(eliminated))\n",
    "                if(commonElmtCnt==0):\n",
    "                    ftSet= np.append(ftSet, list(combo)).astype(int)\n",
    "                    ftAccuracy= crossValidate(data, ftSet )\n",
    "                    print(\"        - Testing with features \"+ str(ftSet) + \" | Accuracy: %\" + str(round(ftAccuracy*100,3)))\n",
    "                    if ftAccuracy>bestAcc:\n",
    "                        bestAcc= ftAccuracy\n",
    "                        bestFts= ftSet\n",
    "                        elimCandidate= list(set(prevFtSet).difference((combo)))[0]\n",
    "        eliminated= np.append(eliminated, elimCandidate).astype(int)\n",
    "        print(\"[-] -- On level \"+str(leveL)+ \", we eliminate feature [\"+ str(elimCandidate)+\"], and end up with feature set: \" + str(bestFts)+\" with an accuracy of %\" + str(round(bestAcc*100,3)))\n",
    "        print(\"                                        [:-:] Eliminated so far:--->\"+ str(eliminated)+ \"\\n\")\n",
    "        if bestAcc>globalAcc:\n",
    "            globalAcc= bestAcc\n",
    "            globalFts= bestFts\n",
    "        return backwardElimination(data, bestFts,eliminated, globalAcc, globalFts)\n",
    "\n",
    "\n",
    "\n",
    "def exhaustiveSelection(data):\n",
    "    bestAcc= 0\n",
    "    for combo in generateCombos(data):\n",
    "        ftSet= np.empty(0)\n",
    "        ftSet= np.append(ftSet, combo).astype(int)\n",
    "        ftAccuracy= crossValidate(data, ftSet )\n",
    "        print(\"        - Testing with features \"+ str(ftSet) + \" | Accuracy: %\" + str(round(ftAccuracy*100,3)))\n",
    "        if ftAccuracy>bestAcc:\n",
    "            bestAcc= ftAccuracy\n",
    "            bestFt= ftSet\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "              \n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# start = timer()\n",
    "# print(forwardSelection(data))\n",
    "# print(\"Time without GPU:\", timer()-start)\n",
    "\n",
    "print(backwardElimination(data, np.asarray([1,2,3,4,5,6])))\n",
    "\n",
    "# print(exhaustiveSelection(data))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **[:+:] Notes**\n",
    "-   The best single feature is #5, with an accuracy of 0.856"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Works Cited:\n",
    "\n",
    "\n",
    "-   https://www.analyticsvidhya.com/blog/2020/02/4-types-of-distance-metrics-in-machine-learning/\n",
    "\n",
    "-   https://www.geeksforgeeks.org/pandas-groupby-count-occurrences-in-column/\n",
    "-   https://www.codingem.com/python-how-to-get-all-combinations-of-a-list/\n",
    "-   https://www.geeksforgeeks.org/running-python-script-on-gpu/\n",
    "-   https://www.programiz.com/python-programming/methods/set/intersection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d452713d07931529b46a6a4adbae9c48126cf3f4bc3a50be39ac3715dec6caaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
