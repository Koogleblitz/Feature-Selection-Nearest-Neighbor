{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **[:+:] -- Feature Selection + Nearest Neighbor -- [:+:]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "#import seaborn as seab\n",
    "from itertools import chain, combinations\n",
    "#from scipy.spatial import minkowski_distance\n",
    "from numba import jit, cuda\n",
    "from timeit import default_timer as timer\n",
    "from math import comb\n",
    "# from itertools import combinations\n",
    "\n",
    "# [:::] --- TodDo  ---\n",
    "# - [x] Find \"default Rate\" : size(most common class)/size(dataset)\n",
    "# - [x] Create Minkowski Distance function for two points\n",
    "# - [x] Find nn of a single data point using only one feature\n",
    "# - [x] Get rid of spurrious percision\n",
    "# - [x] For small data, find nn of every data point using one feature + max accuracy\n",
    "# - [x] For small data, find nn of every data point using all features + max accuracy\n",
    "# - [x] Complete Forward selection for small datas set\n",
    "# - [x] GPU Multithreading for Classifier\n",
    "# - [x] Leave-One-Out Cross Validation\n",
    "# - [x] Complete Backward Elimination for small data set\n",
    "# - [x] Forward selection methods for large data set\n",
    "# - [x] Forward Selection validation for both datasets\n",
    "# - [x] Data Processing funtion\n",
    "# - [] Backelimination for large Data\n",
    "# - [] Data Viz\n",
    "# - [] Report\n",
    "# - [] User UI\n",
    "# - [] Third Feature\n",
    "# - [] Apend Data Processing function with distance matrix formation\n",
    "# - [] multithread everything else\n",
    "# - [] Find more brown m&ms\n",
    "# - [] Clean up the code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[+]** Read and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Convert to numpy array to enable multithreading later:\n",
      "column size after conversion: 7\n",
      "column size after transposition: 500\n",
      "Dimensions after transposition: (7, 500)\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "#Read data from the text files and set as a pandas data frame\n",
    "lilData = pd.read_csv('CS170_Small_Data__19.txt', sep=\"  \", engine='python', header=None)\n",
    "bigData = pd.read_csv('CS170_Large_Data__3.txt', sep=\"  \", engine='python', header=None)\n",
    "\n",
    "print(\"\\nConvert to numpy array to enable multithreading later:\")\n",
    "lilData= lilData.to_numpy()\n",
    "bigData= bigData.to_numpy()\n",
    "print(\"column size after conversion: \" + str(len(lilData[0])))\n",
    "lilData= lilData.transpose()\n",
    "bigData= bigData.transpose()\n",
    "print(\"column size after transposition: \" + str(len(lilData[0])))\n",
    "print(\"Dimensions after transposition: \" + str(lilData.shape))\n",
    "print(type(lilData[0][0]))\n",
    "\n",
    "\n",
    "data= lilData\n",
    "#print all the data:\n",
    "#print(lilData)\n",
    "\n",
    "\n",
    "#----print just the 'label' column (and indeces):\n",
    "# print(\"The first 4 entries of the first column: data[colIdx][rowIdx]:\")\n",
    "# print(data[0][0:5])\n",
    "# print(type(data[0][0]))\n",
    "\n",
    "\n",
    "# print(\"\\nOriginal Matrix Dimensions:\")\n",
    "# lil_rowXcol= data.shape\n",
    "# print(lil_rowXcol)\n",
    "\n",
    "\n",
    "# print(\"Data Head:\")\n",
    "# print(data.head())\n",
    "\n",
    "# print(\"MetaData: \")\n",
    "# lilData.describe()\n",
    "\n",
    "\n",
    "\n",
    "# print('Occurrence counts of classes:')\n",
    "# # count occurrences of the class column\n",
    "# occur = lilData.groupby([0]).size()\n",
    "# # display occurrences of a particular column\n",
    "# display(occur)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[+]** Minkowski Distance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My (from-scratch)Function takes in indices of two data points and exponent p, returns the minkowski distance between them based on the four dimensions and the exponent\n",
    "@jit(target_backend='cuda')\n",
    "def minkowski(data,rowIdx1,rowIdx2,ftSet,p):\n",
    "    # featSet1= []\n",
    "    # featSet2= []\n",
    "    sigma= 0\n",
    "    for ft in ftSet:\n",
    "        # featSet1.append(data[ft][rowIdx1])\n",
    "        # featSet2.append(data[ft][rowIdx2])\n",
    "        sigma+= ((((data[ft][rowIdx1]-data[ft][rowIdx2])**2))**(1/2))  **(p)\n",
    "        distance= sigma**(1/p)\n",
    "    return distance\n",
    "    # return distance, featSet1, featSet2\n",
    "\n",
    "# d= minkowski(lilData, rowIdx1=1, rowIdx2= 2, ftSet=(1,2,3,4,5,6), p=2)\n",
    "# print(d)\n",
    "# minkowski_distance(d[1],d[2],p=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[:+:]** Forward Selection **+** Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "# @jit(nopython=False)\n",
    "def generateFtCombos(data, limit=6):\n",
    "    # features= np.empty(0)\n",
    "    # ftCombos= np.empty(0)\n",
    "    features= np.empty(0).astype(int)\n",
    "    ftCombos= []\n",
    "    ftRow= data.shape[0]\n",
    "    for i in range(1,ftRow):\n",
    "        features= np.append(features, i)\n",
    "    for ft in range(1, limit):\n",
    "        for combo in itertools.combinations(features, ft):\n",
    "            ftCombos.append(combo)\n",
    "    return features, (ftCombos)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# @jit(target_backend='cuda')\n",
    "def generateDefaultRate(data):\n",
    "    classCnt= [0,0]\n",
    "    for pt in data[0]:\n",
    "        if pt==1:\n",
    "            classCnt[0]+= 1\n",
    "        else:\n",
    "            classCnt[1]+= 1\n",
    "    defaultRate= max(classCnt)/(classCnt[0]+classCnt[1])\n",
    "    return defaultRate\n",
    "\n",
    "\n",
    "# takes a single combo of features, classifies each dp by its nearest neighbor, returns a list of classifications for every dp\n",
    "@jit(target_backend='cuda')\n",
    "def classifier(data, ftSet):\n",
    "    rows= data.shape[1]\n",
    "    nearestNeighbors= np.empty(0)\n",
    "    for dp in range(0,rows):\n",
    "        nnIdx= 0\n",
    "        nearest= 10000\n",
    "        classification= 0\n",
    "        for  neighborIdx in range(0,rows):\n",
    "            if dp != neighborIdx:\n",
    "                dist= minkowski(data, dp, neighborIdx, ftSet, p=2)\n",
    "                if dist < nearest:\n",
    "                    nnIdx= neighborIdx\n",
    "                    nearest= dist\n",
    "        classification= data[0][nnIdx]\n",
    "        nearestNeighbors= np.append(nearestNeighbors, classification)\n",
    "    return nearestNeighbors\n",
    "\n",
    "\n",
    "#  Returns the accuracy of the classifier tested with a combination of features (leave-one-out, k=n)\n",
    "# @jit(target_backend='cuda')\n",
    "def crossValidate(data, ftSet):\n",
    "    classes= classifier(data, ftSet)\n",
    "    classesL= len(classes)\n",
    "    correct= 0\n",
    "    for j in range(0,classesL):\n",
    "        if classes[j] == data[0][j]:\n",
    "            correct+=1\n",
    "    accuracy = correct/classesL\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# @jit(target_backend='cuda')\n",
    "def forwardSelection(data, prevFtSet=np.asarray([]),finalAccuracy=0, finalSet=np.asarray([])):\n",
    "    ftSetLen= len(prevFtSet)\n",
    "    ftRowLength= data.shape[0]\n",
    "    if ftSetLen>= ftRowLength-1:\n",
    "        bestFtSet= finalSet\n",
    "        print(\"[:+:] ---  Forward Selection Results: The best set of features is \" +str(bestFtSet)+ \" | Accuracy: %\" +str(round(finalAccuracy*100,3))+ \"  --- [:+:]\")\n",
    "    else:\n",
    "        print(\"[::] -- Forward Selection Search Tree Level \"+str(ftSetLen+1)+ \" -- [::]\" )\n",
    "        if ftSetLen==0:\n",
    "            print(\"        - Testing without features  | Default Rate: %\" + str(round(generateDefaultRate(data)*100,3)))\n",
    "        bestAcc= 0\n",
    "        bestFtSubset= np.empty(0)\n",
    "        for ft in range(1, ftRowLength):\n",
    "            ftSet= np.empty(0)\n",
    "            if ft not in prevFtSet:\n",
    "                ftSet= np.append(prevFtSet, ft).astype(int)\n",
    "                ftAccuracy= crossValidate(data,ftSet)\n",
    "                print(\"        - Testing with features \"+ str(ftSet) + \" | Accuracy: %\" + str(round(ftAccuracy*100,3)))\n",
    "                if ftAccuracy>bestAcc: \n",
    "                    bestAcc= ftAccuracy\n",
    "                    bestFtSubset= ftSet\n",
    "        if bestAcc>finalAccuracy:\n",
    "            finalSet= bestFtSubset\n",
    "            finalAccuracy= bestAcc\n",
    "        print(\"     [+] -- On level \"+str(ftSetLen+1)+ \", we add feature subset \" + str(bestFtSubset)+\" with an accuracy of %\" + str(round(bestAcc*100,3))+ \"\\n\")\n",
    "        bestFtSet=  forwardSelection(data, bestFtSubset,finalAccuracy, finalSet)\n",
    "    return bestFtSet\n",
    "\n",
    "\n",
    "\n",
    "def backwardElimination(data, prevFtSet=np.empty(0), eliminated=np.empty(0), globalAcc=0, globalFts=np.empty(0)):\n",
    "    ftRowL= data.shape[0]\n",
    "    if ftRowL<10:\n",
    "        ftCombos= generateFtCombos(data)[1]\n",
    "    else:\n",
    "        # ftSetNew= (generateFeatures(ftRowL))\n",
    "        # ftCombos= getTriplets(np.asarray(ftSetNew))\n",
    "        ftCombos= generateFtCombos(data,limit=3)[1]\n",
    "    \n",
    "    bestAcc= 0\n",
    "    bestFts= np.empty(0)\n",
    "    prevComboL= len(prevFtSet)\n",
    "    leveL= ftRowL - prevComboL\n",
    "    elimCandidate= []\n",
    "    print(\"[::] -- Backward Elimination Search Tree Level \"+str(leveL)+ \" -- [::]\" )\n",
    "    if(prevComboL==1):\n",
    "        defaultRate= generateDefaultRate(data)\n",
    "        print(\"After eliminating all features, we  und up with a default rate of: \" +str(defaultRate))\n",
    "        print(\"\\n[:+:] ---  Backward Selection Results: The best set of features is \" +str(globalFts)+ \" | Accuracy: %\" +str(round(globalAcc*100,3))+ \"  --- [:+:]\")\n",
    "        return globalFts, globalAcc\n",
    "    else:\n",
    "        if(prevComboL==ftRowL-1):\n",
    "            print(\"        - Testing with features \"+ str(prevFtSet) + \" | Accuracy: %\" + str(round(crossValidate(data, prevFtSet )*100,3)))\n",
    "        for i in range(0, len(ftCombos)):\n",
    "            ftSet= np.empty(0)\n",
    "            combo= set(ftCombos[i])\n",
    "            if (len(combo)==(prevComboL-1)):\n",
    "                commonElmtCnt= len(combo.intersection(eliminated))\n",
    "                if(commonElmtCnt==0):\n",
    "                    ftSet= np.append(ftSet, list(combo)).astype(int)\n",
    "                    ftAccuracy= crossValidate(data, ftSet )\n",
    "                    print(\"        - Testing with features \"+ str(ftSet) + \" | Accuracy: %\" + str(round(ftAccuracy*100,3)))\n",
    "                    if ftAccuracy>bestAcc:\n",
    "                        bestAcc= ftAccuracy\n",
    "                        bestFts= ftSet\n",
    "                        elimCandidate= list(set(prevFtSet).difference((combo)))[0]\n",
    "        eliminated= np.append(eliminated, elimCandidate).astype(int)\n",
    "        print(\"     [-] -- On level \"+str(leveL)+ \", we eliminate feature [\"+ str(elimCandidate)+\"], and end up with feature set: \" + str(bestFts)+\" with an accuracy of %\" + str(round(bestAcc*100,3)))\n",
    "        print(\"                                        [:-:] Eliminated so far:--->\"+ str(eliminated)+ \"\\n\")\n",
    "        if bestAcc>globalAcc:\n",
    "            globalAcc= bestAcc\n",
    "            globalFts= bestFts\n",
    "        return backwardElimination(data, bestFts,eliminated, globalAcc, globalFts)\n",
    "\n",
    "\n",
    "\n",
    "def exhaustiveSelection(data):\n",
    "    bestAcc= 0\n",
    "    bestFt= np.empty(0)\n",
    "    bestTriplet= []\n",
    "    for combo in generateFtCombos(data)[1]:\n",
    "        ftSet= np.empty(0)      \n",
    "        ftSet= np.append(ftSet, combo).astype(int)\n",
    "        ftAccuracy= crossValidate(data, ftSet )\n",
    "        print(\"        - Testing with features \"+ str(ftSet) + \" | Accuracy: %\" + str(round(ftAccuracy*100,3)))\n",
    "        if ftAccuracy>bestAcc:\n",
    "            bestAcc= ftAccuracy\n",
    "            bestFt= ftSet\n",
    "            if len(ftSet)==3:\n",
    "                bestTriplet.append(ftSet)\n",
    "    return bestFt, bestAcc, bestTriplet\n",
    "\n",
    "# @jit(nopython=True)\n",
    "@jit(target_backend='cuda')\n",
    "def generateFeatures(ftRowL=0):\n",
    "    # if ftRowL==0:\n",
    "    #     ftRowL= data.shape[0]\n",
    "    features= np.empty(0)\n",
    "    for i in range(1,ftRowL):\n",
    "        features= np.append(features, i)\n",
    "    return features\n",
    "\n",
    "@jit(target_backend='cuda')\n",
    "def tripleSplits(triplet):\n",
    "    trippled= len(triplet)\n",
    "    size= trippled//3\n",
    "    triSplit= np.empty([size,3])\n",
    "    triSplit= np.empty(0)\n",
    "    for i in range(0,trippled):\n",
    "\n",
    "        if i%3==0:\n",
    "            triSplit[i//3][0]= triplet[i-2]\n",
    "            triSplit[i//3][1]= triplet[i-1]\n",
    "            triSplit[i//3][2]= triplet[i]\n",
    "    return triSplit\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@jit(target_backend='cuda')\n",
    "def generateTriplets(ftRowL, setL=3, prevSet=np.array([]),rezSet= np.empty(0),tripletSet= np.empty(0) ):\n",
    "    if len(prevSet)==setL:\n",
    "        #print(\"return prevset\")\n",
    "        return prevSet\n",
    "    fts= generateFeatures(ftRowL)\n",
    "    for ft in fts:\n",
    "        if ft not in prevSet:\n",
    "            newFtSet= np.copy(prevSet)\n",
    "            newFtSet= np.append(newFtSet,ft)\n",
    "            brandNewFtSet= generateTriplets((ftRowL-1),setL,prevSet=newFtSet, tripletSet=tripletSet)\n",
    "            #print(brandNewFtSet)\n",
    "            tripletSet= np.concatenate(( tripletSet,brandNewFtSet))\n",
    "    #print(\"return tripletSet\")\n",
    "    return tripletSet\n",
    "\n",
    "\n",
    "\n",
    "def getTriplets(ftSet,limit=3):\n",
    "    triplets= []\n",
    "    for comb in itertools.combinations(ftSet, limit):\n",
    "        # comb= (np.asarray(comb))\n",
    "        # triplets= np.append(triplets,comb)\n",
    "        triplets.append(comb)\n",
    "    return (triplets)\n",
    "\n",
    "def bigDataBacklimination(data):\n",
    "    length= data.shape[0]\n",
    "    features= (generateFeatures(ftRowL=length))\n",
    "    #quadruplets= getTriplets(np.asarray(features),4)\n",
    "    triplets= getTriplets(np.asarray(features),3)\n",
    "    doubles= getTriplets(np.asarray(features),2)\n",
    "    singles= getTriplets(np.asarray(features),1)\n",
    "    ftComboList= np.array([ triplets, doubles, singles])\n",
    "    for i in range(0,2):\n",
    "        print(ftComboList[i][0:2])\n",
    "    #ftCombos= generateFtCombos(data,limit=3)[1]\n",
    "    bestGlobalAcc= 0\n",
    "    bestGlobalSet= np.empty(0)\n",
    "    ftGlobals= []\n",
    "    accGlobals= []\n",
    "    exclusion= np.empty(0)\n",
    "    for comboList in ftComboList:\n",
    "        bestLocalAcc= 0\n",
    "        bestLocalSet= np.empty(0)\n",
    "        for  combo in comboList:\n",
    "            common= np.intersect1d(combo, exclusion)\n",
    "            if len(common)==0:\n",
    "                ftSet= np.empty(0)      \n",
    "                ftSet= np.append(ftSet, combo).astype(int)\n",
    "                ftAcc= crossValidate(data, ftSet )\n",
    "                print(\"        - Testing with features \"+ str(ftSet) + \" | Accuracy: %\" + str(round(ftAcc*100,3)))\n",
    "                if ftAcc>bestLocalAcc:\n",
    "                    bestLocalAcc= ftAcc\n",
    "                    bestLocalSet= ftSet\n",
    "        if bestLocalAcc>bestGlobalAcc:\n",
    "            setDiff= np.setdiff1d(bestGlobalSet,bestLocalSet)\n",
    "            exclusion= np.append(exclusion, setDiff)\n",
    "            bestGlobalAcc= bestLocalAcc\n",
    "            bestGlobalSet= bestLocalSet\n",
    "            ftGlobals.append(  (bestLocalAcc,3)  )  \n",
    "            accGlobals.append(  (bestLocalSet,3)  )\n",
    "            print(\"     [-] -- we eliminate feature [\"+ str(setDiff)+\"], and end up with feature set: \" + str(bestLocalSet)+\" with an accuracy of %\" + str(round(bestLocalAcc*100,3)))\n",
    "            print(\"                                        [:-:] Eliminated so far:--->\"+ str(exclusion)+ \"\\n\")\n",
    "    print(\"     [-] -- we eliminate feature [\"+ str(setDiff)+\"], and end up with feature set: \" + str(bestLocalSet)+\" with an accuracy of %\" + str(round(bestLocalAcc*100,3)))\n",
    "    defaultRate= generateDefaultRate(data)\n",
    "    print(\"After eliminating all features, we  und up with a default rate of: \" +str(defaultRate))\n",
    "    print(\"\\n[:+:] ---  Backward Selection Results: The best set of features is \" +str(bestGlobalSet)+ \" | Accuracy: %\" +str(round(bestGlobalAcc*100,3))+ \"  --- [:+:]\")\n",
    "    return ftGlobals, accGlobals\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#-------------------Testing------------------------\n",
    "\n",
    "# bigDataBacklimination(bigData)\n",
    "\n",
    "\n",
    "\n",
    "# start = timer()\n",
    "# print(forwardSelection(lilData))\n",
    "# print(\"Time without GPU:\", timer()-start)\n",
    "\n",
    "# start = timer()\n",
    "# print(backwardElimination(lilData, np.asarray([1,2,3,4,5,6])))\n",
    "# print(\"Time without GPU:\", timer()-start)\n",
    "\n",
    "\n",
    "# start = timer()\n",
    "# print(exhaustiveSelection(lilData))[2]\n",
    "# print(\"Time without GPU:\", timer()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **[:+:] Notes**\n",
    "-   The best single feature is #5, with an accuracy of 0.856"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Works Cited:\n",
    "\n",
    "\n",
    "-   https://www.analyticsvidhya.com/blog/2020/02/4-types-of-distance-metrics-in-machine-learning/\n",
    "\n",
    "-   https://www.geeksforgeeks.org/pandas-groupby-count-occurrences-in-column/\n",
    "-   https://www.codingem.com/python-how-to-get-all-combinations-of-a-list/\n",
    "-   https://www.geeksforgeeks.org/running-python-script-on-gpu/\n",
    "-   https://www.programiz.com/python-programming/methods/set/intersection\n",
    "-   https://www.youtube.com/watch?v=nh2IGC_kLWw\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d452713d07931529b46a6a4adbae9c48126cf3f4bc3a50be39ac3715dec6caaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
