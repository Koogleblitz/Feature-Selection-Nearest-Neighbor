{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **[:+:] Feature Selection + Nearest Neighbor [:+:]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as seab\n",
    "from itertools import chain, combinations\n",
    "#from scipy.spatial import minkowski_distance\n",
    "from numba import jit, cuda\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# - [x] Find \"default Rate\" : size(most common class)/size(dataset)\n",
    "# - [x] Create Minkowski Distance function for two points\n",
    "# - [x] Find nn of a single data point using only one feature\n",
    "# - [] Get rid of spurrious percision\n",
    "# - [x] For small data, find nn of every data point using one feature + max accuracy\n",
    "# - [x] For small data, find nn of every data point using all features + max accuracy\n",
    "# - [x] Complete Forward selection for small datas set\n",
    "# - [] Complete Backward Elimination for small data set\n",
    "# - [] Multithreading\n",
    "# - [] GPU Multithreading\n",
    "# - [x]] Leave-One-Out Cross Validation\n",
    "# - [] Data Viz\n",
    "# - [] Report\n",
    "# - [] Find more brown m&ms\n",
    "# - [] Clean up the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[+] Reading the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 4 entries of the first column: data[colIdx][rowIdx]:\n",
      "0    2.0\n",
      "1    1.0\n",
      "2    2.0\n",
      "3    2.0\n",
      "4    2.0\n",
      "Name: 0, dtype: float64\n",
      "<class 'numpy.float64'>\n",
      "\n",
      "Original Matrix Dimensions:\n",
      "(500, 7)\n",
      "Data Head:\n",
      "     0         1         2         3         4         5         6\n",
      "0  2.0 -1.101866 -0.782026  0.552502  0.454685  1.132363  1.135458\n",
      "1  1.0  0.928979 -0.169694  1.465293 -1.591929  0.144808  0.162709\n",
      "2  2.0  1.123118 -1.384730 -0.903598  0.692522  0.669263 -0.142156\n",
      "3  2.0  0.816617 -0.043628  1.026966  0.231013 -0.006551  2.316509\n",
      "4  2.0 -1.159129 -1.341375  0.459997  0.631261 -1.479455  0.520158\n",
      "MetaData: \n",
      "Occurrence counts of classes:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0\n",
       "1.0     95\n",
       "2.0    405\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Convert to numpy array to enable multithreading later:\n",
      "column size after conversion: 7\n",
      "column size after transposition: 500\n",
      "Dimensions after transposition: (7, 500)\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "#Read data from the text files and set as a pandas data frame\n",
    "data = pd.read_csv('CS170_Small_Data__19.txt', sep=\"  \", engine='python', header=None)\n",
    "\n",
    "\n",
    "#print all the data:\n",
    "#print(lilData)\n",
    "\n",
    "\n",
    "#----print just the 'label' column (and indeces):\n",
    "print(\"The first 4 entries of the first column: data[colIdx][rowIdx]:\")\n",
    "print(data[0][0:5])\n",
    "print(type(data[0][0]))\n",
    "\n",
    "\n",
    "print(\"\\nOriginal Matrix Dimensions:\")\n",
    "lil_rowXcol= data.shape\n",
    "print(lil_rowXcol)\n",
    "\n",
    "\n",
    "print(\"Data Head:\")\n",
    "print(data.head())\n",
    "\n",
    "print(\"MetaData: \")\n",
    "data.describe()\n",
    "\n",
    "\n",
    "\n",
    "print('Occurrence counts of classes:')\n",
    "# count occurrences of the class column\n",
    "occur = data.groupby([0]).size()\n",
    "# display occurrences of a particular column\n",
    "display(occur)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nConvert to numpy array to enable multithreading later:\")\n",
    "data= data.to_numpy()\n",
    "print(\"column size after conversion: \" + str(len(data[0])))\n",
    "data= data.transpose()\n",
    "print(\"column size after transposition: \" + str(len(data[0])))\n",
    "print(\"Dimensions after transposition: \" + str(data.shape))\n",
    "\n",
    "print(type(data[0][0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[+] Minkowski Distance Calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My (from-scratch)Function takes in indices of two data points and exponent p, returns the minkowski distance between them based on the four dimensions and the exponent\n",
    "@jit(target_backend='cuda')\n",
    "def minkowski(data,rowIdx1,rowIdx2,ftSet,p):\n",
    "    # featSet1= []\n",
    "    # featSet2= []\n",
    "     \n",
    "    sigma= 0\n",
    "    for ft in ftSet:\n",
    "        # featSet1.append(data[ft][rowIdx1])\n",
    "        # featSet2.append(data[ft][rowIdx2])\n",
    "        sigma+= ((((data[ft][rowIdx1]-data[ft][rowIdx2])**2))**(1/2))  **(p)\n",
    "        distance= sigma**(1/p)\n",
    "    return distance\n",
    "    # return distance, featSet1, featSet2\n",
    "\n",
    "# d= minkowski(lilData, rowIdx1=1, rowIdx2= 2, ftSet=(1,2,3,4,5,6), p=2)\n",
    "# print(d)\n",
    "# minkowski_distance(d[1],d[2],p=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **[:+:] Forward Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[::] -- Forward Selection Search Tree Level 1 -- [::]\n",
      "        - Testing without features  | Default Rate: %81.0\n",
      "        - Testing with features [1] | Accuracy: %72.4\n",
      "        - Testing with features [2] | Accuracy: %69.2\n",
      "        - Testing with features [3] | Accuracy: %68.0\n",
      "        - Testing with features [4] | Accuracy: %68.6\n",
      "        - Testing with features [5] | Accuracy: %85.6\n",
      "        - Testing with features [6] | Accuracy: %67.0\n",
      "[+] -- On level 1, we add feature subset [5] with an accuracy of %85.6\n",
      "\n",
      "[::] -- Forward Selection Search Tree Level 2 -- [::]\n",
      "        - Testing with features [5 1] | Accuracy: %96.2\n",
      "        - Testing with features [5 2] | Accuracy: %83.2\n",
      "        - Testing with features [5 3] | Accuracy: %82.0\n",
      "        - Testing with features [5 4] | Accuracy: %83.4\n",
      "        - Testing with features [5 6] | Accuracy: %85.4\n",
      "[+] -- On level 2, we add feature subset [5 1] with an accuracy of %96.2\n",
      "\n",
      "[::] -- Forward Selection Search Tree Level 3 -- [::]\n",
      "        - Testing with features [5 1 2] | Accuracy: %91.2\n",
      "        - Testing with features [5 1 3] | Accuracy: %91.4\n",
      "        - Testing with features [5 1 4] | Accuracy: %93.4\n",
      "        - Testing with features [5 1 6] | Accuracy: %94.4\n",
      "[+] -- On level 3, we add feature subset [5 1 6] with an accuracy of %94.4\n",
      "\n",
      "[::] -- Forward Selection Search Tree Level 4 -- [::]\n",
      "        - Testing with features [5 1 6 2] | Accuracy: %91.8\n",
      "        - Testing with features [5 1 6 3] | Accuracy: %89.2\n",
      "        - Testing with features [5 1 6 4] | Accuracy: %88.2\n",
      "[+] -- On level 4, we add feature subset [5 1 6 2] with an accuracy of %91.8\n",
      "\n",
      "[::] -- Forward Selection Search Tree Level 5 -- [::]\n",
      "        - Testing with features [5 1 6 2 3] | Accuracy: %85.0\n",
      "        - Testing with features [5 1 6 2 4] | Accuracy: %84.8\n",
      "[+] -- On level 5, we add feature subset [5 1 6 2 3] with an accuracy of %85.0\n",
      "\n",
      "[::] -- Forward Selection Search Tree Level 6 -- [::]\n",
      "        - Testing with features [5 1 6 2 3 4] | Accuracy: %81.6\n",
      "[+] -- On level 6, we add feature subset [5 1 6 2 3 4] with an accuracy of %81.6\n",
      "\n",
      "[:+:] ---  Forward Selection Results: The best set of features is [5 1] | Accuracy: %96.2  --- [:+:]\n",
      "[5 1]\n"
     ]
    }
   ],
   "source": [
    "# @jit(target_backend='cuda')\n",
    "def generateCombos(data):\n",
    "    features= []\n",
    "    ftRow= data.shape[0]\n",
    "    for i in range(1,ftRow):\n",
    "        features.append(i)\n",
    "    print(features)\n",
    "    return chain.from_iterable(combinations(features, r) for r in range(len(features) + 1))\n",
    "    \n",
    "\n",
    "# @jit(target_backend='cuda')\n",
    "def generateDefaultRate(data):\n",
    "    classCnt= [0,0]\n",
    "    for pt in data[0]:\n",
    "        if pt==1:\n",
    "            classCnt[0]+= 1\n",
    "        else:\n",
    "            classCnt[1]+= 1\n",
    "    defaultRate= max(classCnt)/(classCnt[0]+classCnt[1])\n",
    "    return defaultRate\n",
    "\n",
    "\n",
    "# takes a single combo of features, classifies each dp by its nearest neighbor, returns a list of classifications for every dp\n",
    "@jit(target_backend='cuda')\n",
    "def classifier(data, ftSet):\n",
    "    rows= data.shape[1]\n",
    "    nearestNeighbors= np.empty(0)\n",
    "    for dp in range(0,rows):\n",
    "        nnIdx= 0\n",
    "        nearest= 10000\n",
    "        classification= 0\n",
    "        for  neighborIdx in range(0,rows):\n",
    "            if dp != neighborIdx:\n",
    "                dist= minkowski(data, dp, neighborIdx, ftSet, p=2)\n",
    "                if dist < nearest:\n",
    "                    nnIdx= neighborIdx\n",
    "                    nearest= dist\n",
    "        classification= data[0][nnIdx]\n",
    "        nearestNeighbors= np.append(nearestNeighbors, classification)\n",
    "    return nearestNeighbors\n",
    "\n",
    "\n",
    "#  Returns the accuracy of the classifier tested with a combination of features (leave-one-out, k=n)\n",
    "# @jit(target_backend='cuda')\n",
    "def crossValidate(data, ftSet):\n",
    "    classes= classifier(data, ftSet)\n",
    "    classesL= len(classes)\n",
    "    correct= 0\n",
    "    for j in range(0,classesL):\n",
    "        if classes[j] == data[0][j]:\n",
    "            correct+=1\n",
    "    accuracy = correct/classesL\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# @jit(target_backend='cuda')\n",
    "def forwardSelection(data, prevFtSet=np.asarray([]),finalAccuracy=0, finalSet=np.asarray([])):\n",
    "    ftSetLen= len(prevFtSet)\n",
    "    ftRowLength= data.shape[0]\n",
    "    if ftSetLen>= ftRowLength-1:\n",
    "        bestFtSet= finalSet\n",
    "        print(\"[:+:] ---  Forward Selection Results: The best set of features is \" +str(bestFtSet)+ \" | Accuracy: %\" +str(round(finalAccuracy*100,3))+ \"  --- [:+:]\")\n",
    "    else:\n",
    "        print(\"[::] -- Forward Selection Search Tree Level \"+str(ftSetLen+1)+ \" -- [::]\" )\n",
    "        if ftSetLen==0:\n",
    "            print(\"        - Testing without features  | Default Rate: %\" + str(round(generateDefaultRate(data)*100,3)))\n",
    "        bestAcc= 0\n",
    "        bestFtSubset= np.asarray([])\n",
    "        for ft in range(1, ftRowLength):\n",
    "            ftSet= np.asarray([])\n",
    "            if ft not in prevFtSet:\n",
    "                ftSet= np.append(prevFtSet, ft).astype(int)\n",
    "                ftAccuracy= crossValidate(data,ftSet)\n",
    "                print(\"        - Testing with features \"+ str(ftSet) + \" | Accuracy: %\" + str(round(ftAccuracy*100,3)))\n",
    "                if ftAccuracy>bestAcc: \n",
    "                    bestAcc= ftAccuracy\n",
    "                    bestFtSubset= ftSet\n",
    "        if bestAcc>finalAccuracy:\n",
    "            finalSet= bestFtSubset\n",
    "            finalAccuracy= bestAcc\n",
    "        print(\"[+] -- On level \"+str(ftSetLen+1)+ \", we add feature subset \" + str(bestFtSubset)+\" with an accuracy of %\" + str(round(bestAcc*100,3))+ \"\\n\")\n",
    "        bestFtSet=  forwardSelection(data, bestFtSubset,finalAccuracy, finalSet)\n",
    "    return bestFtSet\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# start = timer()\n",
    "print(forwardSelection(data))\n",
    "# print(\"Time without GPU:\", timer()-start)\n",
    "\n",
    "#classifier(data, ftSet=np.asarray([1,2,3,4]))\n",
    "\n",
    "#print(crossValidate(data,ftSet=np.asarray([1,2,3,4])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **[:+:] Notes**\n",
    "-   The best single feature is #5, with an accuracy of 0.856"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Works Cited:\n",
    "\n",
    "\n",
    "-   https://www.analyticsvidhya.com/blog/2020/02/4-types-of-distance-metrics-in-machine-learning/\n",
    "\n",
    "-   https://www.geeksforgeeks.org/pandas-groupby-count-occurrences-in-column/\n",
    "-   https://www.codingem.com/python-how-to-get-all-combinations-of-a-list/\n",
    "-   https://www.geeksforgeeks.org/running-python-script-on-gpu/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d452713d07931529b46a6a4adbae9c48126cf3f4bc3a50be39ac3715dec6caaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
